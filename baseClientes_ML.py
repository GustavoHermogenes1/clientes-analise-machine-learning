import pandas as pd                                                 # Tratamento e manipula√ß√£o dos dados
from sklearn.preprocessing import StandardScaler, OneHotEncoder     # Normaliza√ß√£o de vari√°veis categ√≥ricas e colocar vari√°veis num√©ricas em mesma escala
from sklearn.cluster import KMeans                                  # Modelo de previs√£o n√£o supervisionado para agrupamento (clusteriza√ß√£o)
from sklearn.compose import ColumnTransformer                       # Aplicar a transforma√ß√£o dos dados no algoritmo
from sklearn.pipeline import Pipeline                               # Pipeline para integrar o pr√©-processamento dos dados e o algoritmo
from sklearn.ensemble import RandomForestClassifier                 # Algoritmo de classifica√ß√£o para classificar os poss√≠veis novos clientes depois de agrupados
from sqlalchemy import create_engine                                # Conex√£o ao banco de dados MySQL


# df_clientes -> base com somente clientes vindo do SGBD
# df_possiveis -> base com leads (poss√≠veis clientes)

'''
    Conex√£o com o banco de dados MySQL via pacote sqlalchemy e importa√ß√£o da tabela clientes para o c√≥digo Python
'''

print("üîß Conectando via SQLAlchemy...")

# Faz a conex√£o usando pymysql como driver e passando os dados de usu√°rio, senha, host e o database do SGBD
engine = create_engine("mysql+pymysql://root:admin@localhost:3306/banco")

# Tratamento de exce√ß√µes em caso de erros de conex√£o
try:
    df_clientes = pd.read_sql("SELECT * FROM clientes", engine)    # Passando como argumentos a query para obter a tabela clientes e o cursor
    print("‚úÖ Dados carregados!")
    print(df_clientes.head())   # Print para visualizar as 5 primeiras linhas da tabela clientes

except Exception as e:
    print("‚ùå Erro ao carregar dados:", e)      # Tratamento do poss√≠vel erro

'''
    Limpeza e tratamento dos dados para preparar o dataset para a an√°lise preditiva
'''

# Comando para ter uma vis√£o geral do data frame e entender sua forma, disposi√ß√£o das colunas e tipos de dados
df_clientes.info()

# Combina√ß√£o das colunas nome e sobrenome em apenas uma para reduzir colunas e otimizar o processo de an√°lise.
df_clientes['Nome'] = df_clientes['Nome']+' '+df_clientes['Sobrenome']

# Exclus√£o de colunas que n√£o agregrar√£o valor ao processo no momento
df_clientes = df_clientes.drop(columns=['Data_Nascimento', 'Telefone', 'Sobrenome', 'Email'])

# Visualizando o dataFrame final que ser√° usado na previs√£o
print(df_clientes.head())

'''
    # Trabalhando com a lista de poss√≠veis clientes # 

    Essa lista foi solicitada ao ChatGPT, por√©m pode ser representada como leads obtidos de campanhas de marketing.

    O modelo preditivo ter√° a fun√ß√£o de analisar as vari√°veis dos registro dessa lista e classific√°-los como poss√≠veis clientes ou n√£o.
'''

# Lista de Leads
possiveis_clientes = [
    {'Idade': 28, 'Escolaridade': 'P√≥s-graduado', 'Estado_Civil': 'Solteiro', 'Renda_Anual': 48000, 'Qtd_Filhos': 0, 'Sexo': 'Feminino'},
    {'Idade': 35, 'Escolaridade': 'Ensino m√©dio',    'Estado_Civil': 'Casado',   'Renda_Anual': 55000, 'Qtd_Filhos': 2, 'Sexo': 'Masculino'},
    {'Idade': 42, 'Escolaridade': 'Parcial', 'Estado_Civil': 'Solteiro', 'Renda_Anual': 30000, 'Qtd_Filhos': 1, 'Sexo': 'Masculino'},
    {'Idade': 24, 'Escolaridade': 'Gradua√ß√£o', 'Estado_Civil': 'Solteiro', 'Renda_Anual': 36000, 'Qtd_Filhos': 0, 'Sexo': 'Feminino'},
    {'Idade': 50, 'Escolaridade': 'Ensino m√©dio',    'Estado_Civil': 'Casado',   'Renda_Anual': 70000, 'Qtd_Filhos': 3, 'Sexo': 'Feminino'},
    {'Idade': 31, 'Escolaridade': 'Gradua√ß√£o', 'Estado_Civil': 'Casado',    'Renda_Anual': 62000, 'Qtd_Filhos': 1, 'Sexo': 'Masculino'},
    {'Idade': 38, 'Escolaridade': 'Parcial', 'Estado_Civil': 'Casado', 'Renda_Anual': 41000, 'Qtd_Filhos': 2, 'Sexo': 'Feminino'},
    {'Idade': 45, 'Escolaridade': 'Ensino m√©dio',    'Estado_Civil': 'Solteiro', 'Renda_Anual': 52000, 'Qtd_Filhos': 2, 'Sexo': 'Masculino'},
    {'Idade': 29, 'Escolaridade': 'Gradua√ß√£o', 'Estado_Civil': 'Solteiro', 'Renda_Anual': 47000, 'Qtd_Filhos': 0, 'Sexo': 'Feminino'},
    {'idade': 60, 'Escolaridade': 'Parcial', 'Estado_Civil': 'Casado', 'Renda_Anual': 39000, 'Qtd_Filhos': 3, 'Sexo': 'Masculino'},
    {'idade': 21, 'Escolaridade': 'Gradua√ß√£o', 'Estado_Civil': 'Casado', 'Renda_Anual': 30000, 'Qtd_Filhos': 0, 'Sexo': 'Masculino'}
]

# Transformando os dados em um DataFrame
df_possiveis = pd.DataFrame(possiveis_clientes)

'''
    # Pr√©-processamento dos dados #

    Essa etapa √© de extrema import√¢ncia para o funcionamento eficaz do modelo de machine learning. √â aqui que ser√£o definidas
    as vari√°veis de interesse, separa√ß√£o das colunas de acordo com o tipo de dado, normaliza√ß√£o e escalonamento dos valores.

    Tendo em vista que a m√°quina n√£o entende textos, ser√° necess√°ria a normaliza√ß√£o dos dados categ√≥ricos utilizando o One Hot Encoder,
    por isso esses valores receber√£o dados bin√°rios (0 e 1). A op√ß√£o pelo OneHotEncoder foi decidido pois n√£o existe uma ordem 
    definida nas vari√°veis. Al√©m disso, os valores num√©ricos passar√£o por um processo para serem colocados em escala usando o
    Standard Scaler e, assim, auxiliar na aprendizagem da m√°quina.
'''
# Definindo as vari√°veis de interesse para o modelo preditivo. 
# Essas vari√°veis ser√£o analisadas pelo modelo. Elas foram definidas como importante pois o agrupamento pode ser feito a partir delas.
variaveis = ['Escolaridade', 'Estado_Civil', 'Sexo', 'Idade', 'Renda_Anual', 'Qtd_Filhos']

# Separando o dataframe da base clientes com as vari√°veis de interesse 
X_clientes = df_clientes[variaveis]

# Colocando o dataframe de leads em uma nova vari√°vel para n√£o alterar o original e manter a legibilidade do c√≥digo
X_possiveis = df_possiveis[variaveis]

# Pr√©-processamento das vari√°veis. Separa√ß√£o das colunas num√©ricas e categ√≥ricas para serem usadas na normaliza√ß√£o e processo de escala.
colunas_numericas = ['Idade', 'Renda_Anual', 'Qtd_Filhos']
colunas_categoricas = ['Escolaridade', 'Estado_Civil', 'Sexo']

# Criando uma inst√¢ncia que ser√° usado como pr√©-processador das vari√°veis
preprocessador = ColumnTransformer([
    ('num', StandardScaler(), colunas_numericas),           # Colocando os valores num√©ricos em escala
    ('cat', OneHotEncoder(drop='first'), colunas_categoricas)   # Normalizando as colunas categ√≥ricas. O drop='first' √© usado ficar com menos colunas e n√£o sobrecarregar.
])

'''
    # Algoritmo KMeans #

    A decis√£o para a utiliza√ß√£o desse algoritmo foi baseada em sua facilidade de manipula√ß√£o e no f√°cil entendimento de seu funcionamento.

    Esse algoritmo √© baseado em c√°lculos matem√°ticos de dist√¢ncia para agrupamentos dos dados.

    √â definido uma quantidade de centroides de acordo com o n√∫mero de clusters (grupos a partir de similaridades) que agrupar√£o os dados.
    O agrupamento √© feito com base no c√°lculo da dist√¢ncia de um dado para todos os centroides, o que tiver a menor dist√¢ncia ser√° o grupo para o dado.
'''

# Pipeline para pr√©-processamento e algoritmo KMeans
# Esse Pipeline √© uma sequ√™ncia de etapas que √© resultado da jun√ß√£o do pr√©-processamento e o algoritmo de agrupamento utilizado
# K-Means √© o algoritmo de agrupamento que ser√° utilizado
pipeline_kmeans = Pipeline(steps=[
    ('preprocessamento', preprocessador),           # Esse √© o pr√©-processamento dos dados feito anteriormente
    ('kmeans', KMeans(n_clusters=3, random_state=1))  # A quantidade de clusters (grupos separados por similaridades) foi definido como 3 e o random state = 1 √© para o c√≥digo gerar o mesmo resultado. 
])

# Treinando o algoritmo K-Means na base de clientes
pipeline_kmeans.fit(X_clientes)

# Obtendo os r√≥tulos dos clusters (agrupamentos com base nas similaridades das vari√°veis)
grupos_clientes = pipeline_kmeans.named_steps['kmeans'].labels_

'''
    # Algoritmo Random Forest #

    Esse algoritmo ser√° utilizado a partir do agrupamento dos dados com o KMeans. Depois dos dados serem agrupados de acordo com as similaridades
    e treinado o algoritmo, precisaremos de um algoritmo classificador para rotular os novos dados a partir dos treinos.

    Ent√£o, basicamente, o KMeans foi utilizado para agrupar os dados com as similaridades e o Random Forest far√° a classifica√ß√£o. Por isso ser√£o utilizados juntos neste c√≥digo.

    O Random Forest √© um algoritmo de classifica√ß√£o com aprendizado supervisionado, ou seja, precisa dos r√≥tulos no dataset.
    A escolha por esse algoritmo foi baseada em sua boa manipula√ß√£o com vari√°veis num√©ricas e categ√≥ricas, evita overfitting (previs√£o muito ajustada nos dados de treino)
    e n√£o precisa de muitos ajustes. Esse algoritmo √© uma floresta de √°rvores de decis√£o (modelo mais simples de machine learning).
'''

# Treinando o algoritmo classificador (neste caso a random forest) para prever o cluster (perfil de poss√≠veis clientes) 
X_clientes_tratado = pipeline_kmeans.named_steps['preprocessamento'].transform(X_clientes) # Aplicando o pr√©-processamento para o algoritmo de classifica√ß√£o
classificador = RandomForestClassifier(random_state=1) # Criando o classificador utilizando o algoritmo random forest
classificador.fit(X_clientes_tratado, grupos_clientes)  # Treinando o classificador com as vari√°veis e seus r√≥tulos

# Tratando o grupo dos poss√≠veis clientes e fazendo a previs√£o de classifica√ß√£o
X_possiveis_tratado = pipeline_kmeans.named_steps['preprocessamento'].transform(X_possiveis) # Aplicando o pr√©-processamento dos dados para a base de poss√≠veis clientes
grupos_possiveis = classificador.predict(X_possiveis_tratado)   # Previs√£o dos grupos dos poss√≠veis clientes

# Adicionando o resultado da previs√£o dos grupos no DataFrame de poss√≠veis clientes
df_possiveis['perfil_cliente'] = ['Sim' if grupo == 1 else 'N√£o' for grupo in grupos_possiveis]

'''
    # Resultado Final #

    O resultado final de fato combina com as an√°lises feitas anteriormente em SQL, evidenciando que o perfil de clientes √© 
    voltado ao p√∫blico casado, escolaridade baixa e de baixa renda.

    Portanto, avalio o resultado final como extremamente positivo e √∫til para a empresa, deixando o processo de an√°lise de dados
    mais eficiente e, claro, possibilitando em um melhor direcionamento de vendas.
'''

# Exibir o resultado final da previs√£o de poss√≠veis clientes
print(df_possiveis[['Escolaridade', 'Estado_Civil', 'Sexo', 'Idade', 'Renda_Anual', 'Qtd_Filhos', 'perfil_cliente']])